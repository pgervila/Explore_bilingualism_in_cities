{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream, OAuthHandler, StreamListener\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import pyprind\n",
    "import deepdish as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import secret codes\n",
    "from twitter_pwd import access_token, access_token_secret, consumer_key, consumer_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_list, texts, langs, locs = [], [], [], []\n",
    "\n",
    "class StdOutListener(StreamListener):\n",
    "    \"\"\" A listener handles tweets are the received from the stream.\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_list = []\n",
    "        self.texts = []\n",
    "        self.langs = []\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        jd = json.loads(data)\n",
    "        self.data_list.append(jd)\n",
    "        self.texts.append(jd['text'])\n",
    "        self.langs.append(jd['lang'])\n",
    "        try:\n",
    "            print(data)\n",
    "            saveFile = open('newtweets.csv', 'a')\n",
    "            saveFile.write(data).encode(\"utf8\")\n",
    "            saveFile.write('/n').encode(\"utf8\")\n",
    "            saveFile.close()\n",
    "            return True\n",
    "        except BaseException:\n",
    "            print ('failed ondata')\n",
    "            time.sleep(5)\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coordinates\n",
    "Lviv = [23.882904,49.763526,24.163055,49.921167]\n",
    "Kiev = [30.449982,50.408518,30.639496,50.495958]\n",
    "Yerevan = [44.329834,40.078071,44.681396,40.296287]\n",
    "Brussel = [4.258575,50.788575,4.489288,50.913424]\n",
    "Barcelona = [1.835403,41.375778,2.241898,41.586688]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Barcelona\n",
    "# l_Barc = StdOutListener()\n",
    "# #ASK FOR KEYWORD TO COLLECT DATA\n",
    "# stream_Barc = Stream(auth, l_Barc)\n",
    "# stream_Barc.filter(locations=Barcelona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Counter(l_Barc.langs)\n",
    "# for data, lang in zip(l_Barc.data_list, l_Barc.langs):\n",
    "#     print(data['user']['location'], lang)\n",
    "for text in l_Barc.texts:\n",
    "    if type(text) == str:\n",
    "        print(text)\n",
    "    else:\n",
    "        print(text.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for ee in l_Barc.data_list:\n",
    "#     print(ee['place']['id'], ee['place']['place_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attributes': {},\n",
       " 'bounding_box': {'coordinates': [[[2.052477, 41.317048],\n",
       "    [2.052477, 41.468266],\n",
       "    [2.229978, 41.468266],\n",
       "    [2.229978, 41.317048]]],\n",
       "  'type': 'Polygon'},\n",
       " 'country': 'España',\n",
       " 'country_code': 'ES',\n",
       " 'full_name': 'Barcelona, España',\n",
       " 'id': '1a27537478dd8e38',\n",
       " 'name': 'Barcelona',\n",
       " 'place_type': 'city',\n",
       " 'url': 'https://api.twitter.com/1.1/geo/id/1a27537478dd8e38.json'}"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_Barc.data_list[1]['place'] #[1.835403,41.375778,2.241898,41.586688]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Brussel\n",
    "# l_Bru = StdOutListener()\n",
    "# #ASK FOR KEYWORD TO COLLECT DATA\n",
    "# stream_Bru = Stream(auth, l_Bru)\n",
    "# stream_Bru.filter(locations=Brussel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Counter(l_Bru.langs)\n",
    "# for data, lang in zip(l_Bru.data_list, l_Bru.langs):\n",
    "#     print(data['user']['location'], lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #LVIV\n",
    "# l_Lv = StdOutListener()\n",
    "# #ASK FOR KEYWORD TO COLLECT DATA\n",
    "# stream_Lv = Stream(auth, l_Lv)\n",
    "# stream_Lv.filter(locations=Lviv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #YEREVAN\n",
    "# l_Yer = StdOutListener()\n",
    "# #ASK FOR KEYWORD TO COLLECT DATA\n",
    "# stream_Yer = Stream(auth, l_Yer)\n",
    "# stream_Yer.filter(locations=Yerevan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for data, lang in zip(l_Yer.data_list, l_Yer.langs):\n",
    "#     print(data['user']['location'], lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for text in l_Yer.texts:\n",
    "#     if type(text) == str:\n",
    "#         print(text)\n",
    "#     else:\n",
    "#         print(text.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for data, lang in zip(data_list, langs):\n",
    "#     print(data['user']['location'], lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'en': 8, 'nl': 1, 'pl': 1, 'ru': 54, 'tl': 1, 'uk': 8, 'und': 6})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KIEV\n",
    "l_Kiev = StdOutListener()\n",
    "#ASK FOR KEYWORD TO COLLECT DATA\n",
    "stream_Kiev = Stream(auth, l_Kiev)\n",
    "stream_Kiev.filter(locations=Kiev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Counter(l_Kiev.langs)\n",
    "# for data, lang in zip(l_Kiev.data_list, l_Kiev.langs):\n",
    "#     print(data['user']['location'], lang)\n",
    "for text in l_Kiev.texts:\n",
    "    if type(text) == str:\n",
    "        print(text)\n",
    "    else:\n",
    "        print(text.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data in l_Kiev.data_list:\n",
    "    print(data['place']['id'], data['place']['place_type'], \n",
    "          data['place']['country'], data['user']['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    if type(text) == str:\n",
    "        print(text)\n",
    "    else:\n",
    "        print(text.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### USERS, FOLLOWERS, TIMELINES, LANGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import re\n",
    "\n",
    "def get_account_network(account_name, rel_type='followers', max_num =100, key_words=None):\n",
    "    pbar = pyprind.ProgBar(max_num)\n",
    "    list_people = []\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    users = tweepy.Cursor(getattr(api, rel_type, 0), screen_name=account_name).items(max_num)\n",
    "    while True:\n",
    "        try:\n",
    "            user = next(users)\n",
    "            if not key_words:\n",
    "                list_people.append(user)\n",
    "            else:\n",
    "                locs = '|'.join(key_words)\n",
    "                patt = re.compile(locs)\n",
    "                found_loc = re.findall(patt, user._json['location'])\n",
    "                if found_loc:\n",
    "                    list_people.append(user)\n",
    "        except tweepy.TweepError as e:\n",
    "            if 'Read timed out' in str(e):\n",
    "                print('fallen here')\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                time.sleep(60*16)\n",
    "                user = next(users)\n",
    "        except StopIteration:\n",
    "            break            \n",
    "        pbar.update()\n",
    "    return list_people\n",
    "    \n",
    "\n",
    "def get_twitter_followers(account_name, max_num=100):\n",
    "    list_followers=[]\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    users = tweepy.Cursor(api.followers, screen_name=account_name).items(max_num)\n",
    "    #i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            #print(i)\n",
    "            user = next(users)\n",
    "            list_followers.append(user)\n",
    "            #i+=1\n",
    "        except tweepy.TweepError as e:\n",
    "            if 'Read timed out' in str(e):\n",
    "                print('fall here')\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                time.sleep(60*16)\n",
    "                user = next(users)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        #print (\"@\" + user.screen_name)\n",
    "    return list_followers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_user_timeline(account_name, max_num=10):\n",
    "    list_tweets=[]\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    timeline = tweepy.Cursor(api.user_timeline, screen_name=account_name).items(max_num)\n",
    "    i=0\n",
    "    while True:\n",
    "        try:\n",
    "            tw = next(timeline)\n",
    "            list_tweets.append(tw)\n",
    "        except tweepy.TweepError as e:\n",
    "            if '401' in str(e):    \n",
    "                print(e)\n",
    "                time.sleep(10)\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(60*15)\n",
    "                tw = next(timeline)\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return list_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_twts_from_list_account_names(list_followers, max_num_followers=None):\n",
    "    pbar = pyprind.ProgBar(len(list_followers))\n",
    "    text_tl_followers=[]\n",
    "    lang_tl_followers=[]\n",
    "    authors = []\n",
    "    if max_num_followers:\n",
    "        list_followers = list_followers[:max_num_followers]\n",
    "    for idx, f in enumerate(list_followers):\n",
    "        #print(idx)\n",
    "        tl = get_user_timeline(f, max_num=10)\n",
    "        text_tl_followers.extend([tw.text for tw in tl])\n",
    "        lang_tl_followers.extend([tw.lang for tw in tl])\n",
    "        authors.extend([f for _ in tl])\n",
    "        pbar.update()\n",
    "    return text_tl_followers, lang_tl_followers, authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words=['Україна', 'Ukraine', 'Украина']\n",
    "hr_lviv_followers = get_account_network('hromadskelviv', rel_type='followers', \n",
    "                                        max_num =100, key_words=key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "json_info = [elem._json for elem in hr_lviv_followers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(json_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/pandas/core/generic.py:939: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->['created_at', 'description', 'entities', 'id_str', 'lang', 'location', 'name', 'profile_background_color', 'profile_background_image_url', 'profile_background_image_url_https', 'profile_banner_url', 'profile_image_url', 'profile_image_url_https', 'profile_link_color', 'profile_sidebar_border_color', 'profile_sidebar_fill_color', 'profile_text_color', 'screen_name', 'status', 'time_zone', 'translator_type', 'url']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df.to_hdf('dfs.h5', '/ukr/lviv/hromadske/followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_in = pd.read_hdf('dfs.h5','/ukr/lviv/hromadske/followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter error response: status code = 401\n",
      "Twitter error response: status code = 401\n",
      "Twitter error response: status code = 401\n"
     ]
    }
   ],
   "source": [
    "vk_texts, vk_langs = get_twts_from_list_account_names(vk_followers, max_num_followers=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ak_followers = get_twitter_followers('auto_kiev', max_num=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'de': 1,\n",
       "         'en': 41,\n",
       "         'es': 1,\n",
       "         'fr': 1,\n",
       "         'pl': 1,\n",
       "         'ru': 464,\n",
       "         'uk': 90,\n",
       "         'zh-cn': 1})"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([f.lang for f in ak_followers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ak_twts = get_user_timeline('auto_kiev', max_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ru': 73, 'uk': 26, 'und': 1})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([tw.lang for tw in ak_twts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txts_ak, langs_ak = get_twts_from_list_account_names(ak_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "und_txt = [txt for txt,lang in zip(txts_ak, langs_ak) if lang == 'it']\n",
    "und_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lang_tl_followers=[]\n",
    "# for idx, f in enumerate(ak_followers[:100]):\n",
    "#     print(idx)\n",
    "#     tl = get_user_timeline(f.screen_name, max_num=100)\n",
    "#     lang_tl_followers.extend([tw.lang for tw in tl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20796656323222087"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts=Counter(langs_ak)\n",
    "counts['uk']/(counts['uk'] + counts['ru'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATALUNYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Catalunya\n",
    "list_acc = ['bcn_ajuntament', 'girona_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aj_bcn_followers = get_twitter_followers('bcn_ajuntament', max_num=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ca': 8, 'en': 4, 'en-gb': 1, 'es': 36, 'zh-cn': 1})"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([f.lang for f in aj_bcn_followers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Herreacruz'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aj_bcn_followers[36].screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter error response: status code = 401\n",
      "Twitter error response: status code = 401\n",
      "Twitter error response: status code = 401\n",
      "Twitter error response: status code = 401\n"
     ]
    }
   ],
   "source": [
    "txts, langs = get_twts_from_list_account_names(aj_bcn_followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(tw, lang) for tw, lang in zip(txts,langs) if lang == 'und']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#langs_detected = [detect(txt) for txt in txts if len(txts) > 10]\n",
    "langs_detected=[]\n",
    "for i,txt in enumerate(txts):\n",
    "    #print(i, txt)\n",
    "    try:\n",
    "        langs_detected.append(detect(txt))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aj_gr_followers = get_twitter_followers('girona_cat', max_num=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aj_gr_twts = get_user_timeline('girona_cat', max_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ca': 76, 'de': 1, 'en': 26, 'es': 91, 'fr': 3, 'ja': 1, 'pt': 2})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([f.lang for f in aj_gr_followers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "866377201733775360"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aj_gr_twts[2].id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UKRAINE: data structure and relevant twitter accounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ukraine_nodes = {}\n",
    "Ukraine_nodes['cities'] = ['kiev', 'odessa', 'lviv', 'kharkov', 'dnipropetrovsk']\n",
    "Ukraine_nodes['city_sites'] = {'Mariupol':['0629ComUa'], \n",
    "                               'kiev':['kievtypical','kliniki_kiev','LISOD_clinic','avto_kiev', 'editbeauty']}\n",
    "Ukraine_nodes['news'] = ['HromadskeUA','tsnua','ukrpravda_news', 'lb_ua', 'Korrespondent', \n",
    "                         'Delo_ua', 'BBC_ua', 'LIGAnet', 'segodnya_life']\n",
    "Ukraine_nodes['TV'] = ['5channel', 'EspresoTV', '24tvua', 'footballua_tv']\n",
    "Ukraine_nodes['starsystem'] = ['VeraBrezhneva', 's_vakarchuk', 'KAMEHCKUX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words=['Україна', 'Ukraine', 'Украина', 'Київ', 'Киев']\n",
    "HromadskeUA_followers = get_account_network('HromadskeUA', rel_type='followers', \n",
    "                                            max_num =5000, key_words=key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[#                             ] | ETA: 00:01:55"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 895\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[###                           ] | ETA: 02:20:11"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 893\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#####                         ] | ETA: 02:36:35"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 892\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#######                       ] | ETA: 02:33:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 893\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#########                     ] | ETA: 02:25:42"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 893\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##########                    ] | ETA: 02:37:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 892\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[############                  ] | ETA: 02:21:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 894\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############                ] | ETA: 02:05:57"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 894\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[################              ] | ETA: 01:50:38"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 894\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##################            ] | ETA: 01:34:40"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 892\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[###################           ] | ETA: 01:31:09"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 892\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#####################         ] | ETA: 01:14:26"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 893\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#######################       ] | ETA: 00:57:45"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 891\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#########################     ] | ETA: 01:18:15"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 891\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[###########################   ] | ETA: 00:45:12"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 890\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[############################  ] | ETA: 00:30:10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 889\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "\n",
      "Total time elapsed: 07:19:01\n",
      "//anaconda/lib/python3.5/site-packages/pandas/core/generic.py:939: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->['created_at', 'description', 'entities', 'id_str', 'lang', 'location', 'name', 'profile_background_color', 'profile_background_image_url', 'profile_background_image_url_https', 'profile_banner_url', 'profile_image_url', 'profile_image_url_https', 'profile_link_color', 'profile_sidebar_border_color', 'profile_sidebar_fill_color', 'profile_text_color', 'screen_name', 'status', 'time_zone', 'translator_type', 'url']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n"
     ]
    }
   ],
   "source": [
    "acc_name = 'BBC_ua'\n",
    "key_words=['Україна', 'Ukraine', 'Украина', 'Київ', 'Киев']\n",
    "followers = get_account_network(acc_name, rel_type='followers', \n",
    "                                max_num =5000, key_words=None)\n",
    "json_format = [elem._json for elem in followers]\n",
    "df = pd.DataFrame(json_format)\n",
    "df.to_hdf('lang_data.h5', '/ukr_nodes/news/' + acc_name + '/followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_name = 'LIGAnet'\n",
    "df = pd.read_hdf('lang_data.h5', '/ukr_nodes/news/' + acc_name + '/followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ru    420\n",
       "uk    154\n",
       "en     21\n",
       "it      1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lang'][df['location'].str.contains(r\"(Україна|Ukraine|Украина|Київ|Киев)\")].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_name        501\n",
       "statuses_count     501\n",
       "followers_count    501\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[df['statuses_count'] >= 5][['screen_name', 'statuses_count','followers_count']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HRMUA_flwrs = [f for idx, f in df_HRMUA.iterrows()]\n",
    "#HRMUA_texts, HRMUA_langs = get_twts_from_list_account_names(HRMUA_flwrs, max_num_followers=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_txts_langs_HRMUA = pd.DataFrame({'texts':HRMUA_texts, 'lang':HRMUA_langs})\n",
    "\n",
    "df_txts_langs_HRMUA.to_hdf('lang_data.h5', '/ukr_nodes/news/HromadskeUA/tls_followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_txts = pd.read_hdf('lang_data.h5', '/ukr_nodes/news/HromadskeUA/tls_followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ru     1317\n",
       "uk      766\n",
       "und     552\n",
       "en      185\n",
       "pl        9\n",
       "bg        6\n",
       "cs        3\n",
       "sr        3\n",
       "es        3\n",
       "ko        1\n",
       "it        1\n",
       "el        1\n",
       "ht        1\n",
       "ka        1\n",
       "et        1\n",
       "sl        1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txts['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATALONIA NODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Catalonia_nodes = {}\n",
    "Catalonia_nodes['news'] = ['LaVanguardia', 'VilaWeb', 'diariARA', 'elperiodico',\n",
    "                           'elperiodico_cat', 'elpuntavui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country = 'cat'\n",
    "screen_name = 'VilaWeb'\n",
    "path_save = '/' + country + '_nodes/news/' + screen_name + '/followers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words=['Catal', 'Bcn', 'Barcel']\n",
    "followers = get_account_network(screen_name, rel_type='followers', \n",
    "                                max_num =5000, key_words=None)\n",
    "json_info = [elem._json for elem in followers]\n",
    "df = pd.DataFrame(json_info)\n",
    "df.to_hdf('lang_data.h5', path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ARA_followers = get_account_network('diariARA', rel_type='followers', \n",
    "                                       max_num =5000, key_words=None)\n",
    "json_info_ARA = [elem._json for elem in ARA_followers]\n",
    "df_ARA = pd.DataFrame(json_info_ARA)\n",
    "df_ARA.to_hdf('lang_data.h5', '/cat_nodes/news/diariARA/followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ARA_follwrs = pd.read_hdf('lang_data.h5', '/cat_nodes/news/diariARA/followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "es       240\n",
       "ca       178\n",
       "en        41\n",
       "it         1\n",
       "fr         1\n",
       "en-GB      1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ARA_follwrs[df_ARA_follwrs['statuses_count'] > 5][['screen_name', 'statuses_count','followers_count']].count()\n",
    "df_ARA_follwrs['lang'][df_ARA_follwrs['statuses_count'] > 5][df_ARA_follwrs['location'].str.contains(r\"(Barcel|Catal)\")].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "counts_ARA_Cat = df_ARA['lang'][df_ARA['location'].str.contains(r\"(Barcel|Catal)\")].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13139999999999999"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ARA['lang'][df_ARA['location'].str.contains(r\"(Barcel|Catal|Tarr|Llei|Ger|Gir|Badal)\")].count()/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_LaVang[['lang', 'screen_name']][df_LaVang['location'].str.contains(r\"(Barcel|Catal)\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET TWEETS FROM FOLLOWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country = 'ukr'\n",
    "screen_name = 'LIGAnet'\n",
    "path_load = '/' + country + '_nodes/news/' + screen_name + '/followers'\n",
    "path_save = '/' + country + '_nodes/news/' + screen_name + '/tls_followers'\n",
    "key_words = {'ukr':r\"(Україна|Ukraine|Украина|Київ|Киев|Львів|Одес)\", \n",
    "             'cat':r\"(Barcel|Catal|Tarr|Llei|Ger|Gir|Badal)\"}\n",
    "df = pd.read_hdf('lang_data.h5', path_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tl_followers(screen_name, country, min_num_twts_per_acc=5, max_num_followers=None):\n",
    "    path_load = '/' + country + '_nodes/news/' + screen_name + '/followers'\n",
    "    path_save = '/' + country + '_nodes/news/' + screen_name + '/tls_followers'\n",
    "    key_words = {'ukr':r\"(Україна|Ukraine|Украина|Київ|Киев|Львів|Одес)\", \n",
    "                 'cat':r\"(Barcel|Catal|Tarr|Llei|Ger|Gir|Badal)\"}\n",
    "    df = pd.read_hdf('lang_data.h5', path_load)\n",
    "    # filter by num_min_twts_per_account\n",
    "    relevant_followers = df['screen_name'][df['statuses_count'] >= min_num_twts_per_acc]\n",
    "    # keep only country residents\n",
    "    relevant_followers = relevant_followers[df['location'].str.contains(key_words[country])].values\n",
    "    texts, langs, auth = get_twts_from_list_account_names(relevant_followers, \n",
    "                                                 max_num_followers=max_num_followers)\n",
    "    df_txts_langs= pd.DataFrame({'texts':texts, 'lang':langs, 'screen_name':auth})\n",
    "    df_txts_langs.to_hdf('lang_data.h5', path_save)\n",
    "    return \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df['lang'][df['location'].str.contains(key_words)].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "# filter followers to focus on most relevant ones\n",
    "min_num_twts = 5\n",
    "relevant_followers = df['screen_name'][df['statuses_count'] >= min_num_twts][\n",
    "                         df['location'].str.contains(key_words[country])\n",
    "                       ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[#####                         ] | ETA: 00:01:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter error response: status code = 401\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#########                     ] | ETA: 00:01:37"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#############                 ] | ETA: 00:01:22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############                ] | ETA: 00:01:27"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[####################          ] | ETA: 00:00:50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[######################        ] | ETA: 00:00:42"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[########################      ] | ETA: 00:00:33"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:02:40\n"
     ]
    }
   ],
   "source": [
    "# get twts, lang, authors. Transform to pandas df and save\n",
    "texts, langs, auth = get_twts_from_list_account_names(relevant_followers, max_num_followers=125)\n",
    "df_txts_langs= pd.DataFrame({'texts':texts, 'lang':langs, 'screen_name':auth})\n",
    "df_txts_langs.to_hdf('lang_data.h5', path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ru     499\n",
       "uk     210\n",
       "und    205\n",
       "en     111\n",
       "bg       8\n",
       "ko       5\n",
       "cs       4\n",
       "pl       3\n",
       "in       3\n",
       "sl       2\n",
       "es       2\n",
       "ja       2\n",
       "tl       1\n",
       "sr       1\n",
       "pt       1\n",
       "de       1\n",
       "fr       1\n",
       "no       1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_txts_langs['lang'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_txts_langs['lang'].value_counts()\n",
    "#langs_detected = [detect(txt) for txt in df_txts_langs['texts']]\n",
    "\n",
    "langs_detected=[]\n",
    "for txt in df_txts_langs['texts']:\n",
    "    try:\n",
    "        langs_detected.append(detect(txt))\n",
    "    except:\n",
    "        langs_detected.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'cy': 22,\n",
       "         'ca': 3389,\n",
       "         'no': 19,\n",
       "         'cs': 2,\n",
       "         'es': 5831,\n",
       "         None: 151,\n",
       "         'fa': 3,\n",
       "         'sq': 2,\n",
       "         'ko': 2,\n",
       "         'id': 69,\n",
       "         'lv': 2,\n",
       "         'da': 15,\n",
       "         'pt': 365,\n",
       "         'pl': 5,\n",
       "         'sw': 14,\n",
       "         'sv': 28,\n",
       "         'sk': 13,\n",
       "         'af': 15,\n",
       "         'zh-cn': 9,\n",
       "         'hu': 13,\n",
       "         'en': 1488,\n",
       "         'fi': 31,\n",
       "         'lt': 17,\n",
       "         'de': 53,\n",
       "         'sl': 46,\n",
       "         'fr': 100,\n",
       "         'nl': 26,\n",
       "         'so': 41,\n",
       "         'ur': 80,\n",
       "         'it': 156,\n",
       "         'et': 60,\n",
       "         'vi': 5,\n",
       "         'hr': 16,\n",
       "         'ro': 54,\n",
       "         'tl': 31,\n",
       "         'tr': 8})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_txts_langss_langs['langs_detected'] = langs_detected\n",
    "Counter(langs_detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_try = pd.DataFrame({'a':['aaaa','bbbfdde',1],'b':[23,44,56]})\n",
    "df_try2 = pd.DataFrame({'a':['xxxx','zzzz'],'b':[3233,43214]})\n",
    "\n",
    "store = pd.HDFStore('try_hyerar.h5')\n",
    "\n",
    "store.append('city/topic', df_try)\n",
    "\n",
    "store.close()\n",
    "\n",
    "pd.read_hdf('try_hyerar.h5', 'city/topic')\n",
    "\n",
    "store = pd.HDFStore('try_hyerar.h5','a')\n",
    "\n",
    "store.append('city/topic', df_try2)\n",
    "\n",
    "store.close()\n",
    "\n",
    "pd.read_hdf('try_hyerar.h5', 'city/topic')\n",
    "\n",
    "store = pd.HDFStore('try_hyerar.h5','a')\n",
    "\n",
    "store.put('city/followers',df)\n",
    "\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MY ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = tweepy.API(auth)\n",
    "user_info = api.get_user('ArnauAndreu')  \n",
    "user_info._json['lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ukraine'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info._json['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_friends = get_account_network('ArnauAndreu')\n",
    "\n",
    "my_df = pd.DataFrame(my_followers)\n",
    "\n",
    "Counter([friend.lang for friend in my_friends])\n",
    "\n",
    "my_fr_txts, my_friends_lang = get_twts_from_list_account_names(my_friends)\n",
    "\n",
    "#Counter(my_friends_lang)\n",
    "\n",
    "\n",
    "\n",
    "# my_fr_langs_detected=[]\n",
    "# for i,txt in enumerate(my_fr_txts):\n",
    "#     #print(i, txt)\n",
    "#     try:\n",
    "#         my_fr_langs_detected.append(detect(txt))\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "#Counter(my_fr_langs_detected)\n",
    "\n",
    "usr_tl = get_user_timeline(my_friends[44].screen_name, max_num=10)\n",
    "\n",
    "df_try=pd.DataFrame([twt._json for twt in usr_tl])\n",
    "df_try.columns\n",
    "\n",
    "my_tl = get_user_timeline('ArnauAndreu', max_num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DYNAMO KIEV PLAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DYNAMO PLAYERS\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"http://www.worldfootball.net/teams/dinamo-kiev/2017/2/\"\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.text, \"lxml\")\n",
    "\n",
    "dynamo_players = pd.read_html(url, encoding='utf8')[1][2].dropna().values\n",
    "\n",
    "dynamo_players\n",
    "\n",
    "dyn_play_countr = pd.read_html(url, encoding='utf8')[1][[2,4]].dropna().values\n",
    "\n",
    "dyn_play_countr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PYMONGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "conn=MongoClient()\n",
    "\n",
    "#define database\n",
    "db = conn.citylangs\n",
    "\n",
    "#define collection inside database\n",
    "collection = db.bcn.ajuntam.followers\n",
    "\n",
    "# function to add documents to collection \n",
    "def make_followers_collection(account_name, collection, max_num=100):\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    users = tweepy.Cursor(api.followers, screen_name=account_name).items(max_num)\n",
    "    #i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            user = next(users)\n",
    "            collection.insert_one(user._json)\n",
    "        except tweepy.TweepError as e:\n",
    "            if 'Read timed out' in str(e):\n",
    "                print('fall here')\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                time.sleep(60*16)\n",
    "                user = next(users)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        #print (\"@\" + user.screen_name)\n",
    "    #return collection\n",
    "\n",
    "make_followers_collection('bcn_ajuntament',collection, max_num=100)\n",
    "\n",
    "#check what databases are available\n",
    "conn.database_names()\n",
    "\n",
    "# available collections inside db\n",
    "db.collection_names()\n",
    "\n",
    "collection2 = db.kiev.ukrpravda\n",
    "\n",
    "make_followers_collection('ukrpravda_news',collection2, max_num=300)\n",
    "\n",
    "l = list(conn.citylangs.kiev.ukrpravda.find())\n",
    "\n",
    "Counter([obj['lang'] for obj in l])\n",
    "\n",
    "\n",
    "db.collection_names()\n",
    "\n",
    "#db.categories.insert_one({ \"_id\": \"ukr_pravda\", \"children\": [] })\n",
    "# db.categories.insert({ _id: \"avto_kiev\", children: [] })\n",
    "# db.categories.insert({ _id: \"kiev\", children: [\"ukr_pravda\", \"avto_kiev\"] })\n",
    "\n",
    "db['kiev'].insert_one({'avto_kiev':[],'vitklitschko':[]})\n",
    "\n",
    "db.collection_names()\n",
    "\n",
    "rr=list(db['bcn.ajuntam.followers'].find())\n",
    "\n",
    "db['kiev'].find_one()\n",
    "\n",
    "db['bcn.ajuntam.followers']\n",
    "\n",
    "conn.database_names()\n",
    "\n",
    "coll2 = db.countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get hdf database keys\n",
    "with pd.HDFStore('lang_data.h5','r') as f:\n",
    "    my_keys = f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ukr_nodes/news/BBC_ua/followers',\n",
       " '/ukr_nodes/news/BBC_ua/tls_followers',\n",
       " '/ukr_nodes/news/HromadskeUA/followers',\n",
       " '/ukr_nodes/news/HromadskeUA/tls_followers',\n",
       " '/ukr_nodes/news/LIGAnet/followers',\n",
       " '/ukr_nodes/news/ukrpravda_news/followers',\n",
       " '/cat_nodes/news/LaVanguardia/followers',\n",
       " '/cat_nodes/news/LaVanguardia/tls_followers',\n",
       " '/cat_nodes/news/diariARA/followers',\n",
       " '/cat_nodes/news/diariARA/tls_followers']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'lang_data.h5'\n",
    "country = 'cat'\n",
    "acc_names = ['diariARA', 'LaVanguardia']\n",
    "load_node1 = '/' + country + '_nodes/news/' + acc_names[0] + '/tls_followers'\n",
    "load_node2 = '/' + country + '_nodes/news/' + acc_names[1] + '/tls_followers'\n",
    "\n",
    "df1 = pd.read_hdf(file_path, load_node1)\n",
    "df2 = pd.read_hdf(file_path, load_node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df1, df2, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44937, 2), (34461, 2), (12181, 2))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape, df1.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12a432550>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
