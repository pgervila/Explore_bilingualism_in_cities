{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream, OAuthHandler, StreamListener\n",
    "import json\n",
    "import time\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import pyprind\n",
    "import deepdish as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import secret codes\n",
    "from twitter_pwd import access_token, access_token_secret, consumer_key, consumer_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get random tweets from a given coordinate box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "data_list, texts, langs, locs = [], [], [], []\n",
    "\n",
    "class StdOutListener(StreamListener):\n",
    "    \"\"\" A listener handles tweets are the received from the stream.\n",
    "    This is a basic listener that just prints received tweets to stdout.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_list = []\n",
    "        self.texts = []\n",
    "        self.langs = []\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        jd = json.loads(data)\n",
    "        self.data_list.append(jd)\n",
    "        self.texts.append(jd['text'])\n",
    "        self.langs.append(jd['lang'])\n",
    "        try:\n",
    "            print(data)\n",
    "            saveFile = open('newtweets.csv', 'a')\n",
    "            saveFile.write(data).encode(\"utf8\")\n",
    "            saveFile.write('/n').encode(\"utf8\")\n",
    "            saveFile.close()\n",
    "            return True\n",
    "        except BaseException:\n",
    "            print ('failed ondata')\n",
    "            time.sleep(5)\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coordinates\n",
    "Lviv = [23.882904,49.763526,24.163055,49.921167]\n",
    "Kiev = [30.449982,50.408518,30.639496,50.495958]\n",
    "Yerevan = [44.329834,40.078071,44.681396,40.296287]\n",
    "Brussel = [4.258575,50.788575,4.489288,50.913424]\n",
    "Barcelona = [1.835403,41.375778,2.241898,41.586688]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Barcelona\n",
    "# l_Barc = StdOutListener()\n",
    "# #ASK FOR KEYWORD TO COLLECT DATA\n",
    "# stream_Barc = Stream(auth, l_Barc)\n",
    "# stream_Barc.filter(locations=Barcelona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Counter(l_Barc.langs)\n",
    "# for data, lang in zip(l_Barc.data_list, l_Barc.langs):\n",
    "#     print(data['user']['location'], lang)\n",
    "for text in l_Barc.texts:\n",
    "    if type(text) == str:\n",
    "        print(text)\n",
    "    else:\n",
    "        print(text.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for ee in l_Barc.data_list:\n",
    "#     print(ee['place']['id'], ee['place']['place_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Brussel\n",
    "# l_Bru = StdOutListener()\n",
    "# #ASK FOR KEYWORD TO COLLECT DATA\n",
    "# stream_Bru = Stream(auth, l_Bru)\n",
    "# stream_Bru.filter(locations=Brussel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Counter(l_Bru.langs)\n",
    "# for data, lang in zip(l_Bru.data_list, l_Bru.langs):\n",
    "#     print(data['user']['location'], lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #LVIV\n",
    "# l_Lv = StdOutListener()\n",
    "# #ASK FOR KEYWORD TO COLLECT DATA\n",
    "# stream_Lv = Stream(auth, l_Lv)\n",
    "# stream_Lv.filter(locations=Lviv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #YEREVAN\n",
    "# l_Yer = StdOutListener()\n",
    "# #ASK FOR KEYWORD TO COLLECT DATA\n",
    "# stream_Yer = Stream(auth, l_Yer)\n",
    "# stream_Yer.filter(locations=Yerevan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for data, lang in zip(l_Yer.data_list, l_Yer.langs):\n",
    "#     print(data['user']['location'], lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for text in l_Yer.texts:\n",
    "#     if type(text) == str:\n",
    "#         print(text)\n",
    "#     else:\n",
    "#         print(text.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for data, lang in zip(data_list, langs):\n",
    "#     print(data['user']['location'], lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#KIEV\n",
    "l_Kiev = StdOutListener()\n",
    "#ASK FOR KEYWORD TO COLLECT DATA\n",
    "stream_Kiev = Stream(auth, l_Kiev)\n",
    "stream_Kiev.filter(locations=Kiev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Counter(l_Kiev.langs)\n",
    "# for data, lang in zip(l_Kiev.data_list, l_Kiev.langs):\n",
    "#     print(data['user']['location'], lang)\n",
    "for text in l_Kiev.texts:\n",
    "    if type(text) == str:\n",
    "        print(text)\n",
    "    else:\n",
    "        print(text.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data in l_Kiev.data_list:\n",
    "    print(data['place']['id'], data['place']['place_type'], \n",
    "          data['place']['country'], data['user']['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for text in texts:\n",
    "    if type(text) == str:\n",
    "        print(text)\n",
    "    else:\n",
    "        print(text.decode('utf-8'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KEY FUNCTIONS : USERS, FOLLOWERS, TIMELINES, LANGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import re\n",
    "\n",
    "def get_account_network(account_name, rel_type='followers', max_num =100, key_words=None):\n",
    "    pbar = pyprind.ProgBar(max_num)\n",
    "    list_people = []\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    users = tweepy.Cursor(getattr(api, rel_type, 0), screen_name=account_name).items(max_num)\n",
    "    while True:\n",
    "        try:\n",
    "            user = next(users)\n",
    "            if not key_words:\n",
    "                list_people.append(user)\n",
    "            else:\n",
    "                locs = '|'.join(key_words)\n",
    "                patt = re.compile(locs)\n",
    "                found_loc = re.findall(patt, user._json['location'])\n",
    "                if found_loc:\n",
    "                    list_people.append(user)\n",
    "        except tweepy.TweepError as e:\n",
    "            if 'Read timed out' in str(e):\n",
    "                print('fallen here')\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                time.sleep(60*16)\n",
    "                user = next(users)\n",
    "        except StopIteration:\n",
    "            break            \n",
    "        pbar.update()\n",
    "    return list_people\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_account_timeline(account_name, max_num_twts=10):\n",
    "    \"\"\" Given an account name,\n",
    "        it retrieves a maximum number of tweets stored in a list\n",
    "        Args:\n",
    "            * account name: string. Screen_name that identifies the twitter account\n",
    "            * max_num_twts: integer. Maximum number of tweets to be retrieved for each account\n",
    "        Returns:\n",
    "            * list_tweets: list of strings including all retrieved tweets\"\"\"\n",
    "    list_tweets=[]\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    timeline = tweepy.Cursor(api.user_timeline, screen_name=account_name).items(max_num_twts)\n",
    "    i=0\n",
    "    while True:\n",
    "        try:\n",
    "            tw = next(timeline)\n",
    "            list_tweets.append(tw)\n",
    "        except tweepy.TweepError as e:\n",
    "            if '401' in str(e):    \n",
    "                print(e)\n",
    "                time.sleep(10)\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(60*15)\n",
    "                tw = next(timeline)\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return list_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_twts_from_list_account_names(list_accounts, max_num_accounts=None, max_num_twts=10):\n",
    "    pbar = pyprind.ProgBar(len(list_accounts))\n",
    "    texts_tweets = []\n",
    "    langs_tweets = []\n",
    "    authors_tweets = []\n",
    "    if max_num_accounts:\n",
    "        list_accounts = list_accounts[:max_num_accounts]\n",
    "    for idx, f in enumerate(list_accounts):\n",
    "        #print(idx)\n",
    "        tl = get_account_timeline(f, max_num_twts=max_num_twts)\n",
    "        texts_tweets.extend([tw.text for tw in tl])\n",
    "        langs_tweets.extend([tw.lang for tw in tl])\n",
    "        authors_tweets.extend([f for _ in tl])\n",
    "        pbar.update()\n",
    "    return texts_tweets, langs_tweets, authors_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UKRAINE: data structure and relevant twitter accounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ukraine_nodes = {}\n",
    "Ukraine_nodes['cities'] = ['kiev', 'odessa', 'lviv', 'kharkov', 'dnipropetrovsk']\n",
    "Ukraine_nodes['city_sites'] = {'Mariupol':['0629ComUa'], \n",
    "                               'kiev':['kievtypical','kliniki_kiev','LISOD_clinic','avto_kiev', 'editbeauty']}\n",
    "Ukraine_nodes['news'] = ['HromadskeUA','tsnua','ukrpravda_news', 'lb_ua', 'Korrespondent', \n",
    "                         'Delo_ua', 'BBC_ua', 'LIGAnet', 'segodnya_life']\n",
    "Ukraine_nodes['TV'] = ['5channel', 'EspresoTV', '24tvua', 'footballua_tv']\n",
    "Ukraine_nodes['starsystem'] = ['VeraBrezhneva', 's_vakarchuk', 'KAMEHCKUX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words=['Україна', 'Ukraine', 'Украина', 'Київ', 'Киев']\n",
    "HromadskeUA_followers = get_account_network('HromadskeUA', rel_type='followers', \n",
    "                                            max_num =5000, key_words=key_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[#                             ] | ETA: 00:01:56"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 895\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[###                           ] | ETA: 02:20:50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 896\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#####                         ] | ETA: 02:35:48"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 894\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#######                       ] | ETA: 02:35:37"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 894\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#########                     ] | ETA: 02:26:43"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 894\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##########                    ] | ETA: 02:36:35"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 894\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[############                  ] | ETA: 02:20:50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 895\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############                ] | ETA: 02:04:59"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 891\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[################              ] | ETA: 01:49:41"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 892\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##################            ] | ETA: 01:34:23"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 892\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[###################           ] | ETA: 01:31:16"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 893\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#####################         ] | ETA: 01:14:13"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 884\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#######################       ] | ETA: 00:57:36"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 892\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#########################     ] | ETA: 00:41:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 893\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[###########################   ] | ETA: 00:24:32"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 894\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[############################  ] | ETA: 00:16:52"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n",
      "Rate limit reached. Sleeping for: 892\n",
      "fallen here"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "\n",
      "Total time elapsed: 04:12:35\n",
      "//anaconda/lib/python3.5/site-packages/pandas/core/generic.py:939: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block3_values] [items->['created_at', 'description', 'entities', 'id_str', 'lang', 'location', 'name', 'profile_background_color', 'profile_background_image_url', 'profile_background_image_url_https', 'profile_banner_url', 'profile_image_url', 'profile_image_url_https', 'profile_link_color', 'profile_sidebar_border_color', 'profile_sidebar_fill_color', 'profile_text_color', 'screen_name', 'status', 'time_zone', 'translator_type', 'url']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)\n"
     ]
    }
   ],
   "source": [
    "country = 'ukr'\n",
    "node_name = 'starsystem'\n",
    "acc_name = 's_vakarchuk'\n",
    "rel_type = 'followers'\n",
    "\n",
    "#key_words=['Україна', 'Ukraine', 'Украина', 'Київ', 'Киев']\n",
    "path_save = '/'.join(['',country, node_name, acc_name, rel_type])\n",
    "followers = get_account_network(acc_name, rel_type=rel_type, \n",
    "                                max_num =5000, key_words=None)\n",
    "json_format = [elem._json for elem in followers]\n",
    "df = pd.DataFrame(json_format)\n",
    "df.to_hdf('lang_data.h5', path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_name = 'LIGAnet'\n",
    "df = pd.read_hdf('lang_data.h5', '/ukr_nodes/news/' + acc_name + '/followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ru    420\n",
       "uk    154\n",
       "en     21\n",
       "it      1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lang'][df['location'].str.contains(r\"(Україна|Ukraine|Украина|Київ|Киев)\")].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "screen_name        501\n",
       "statuses_count     501\n",
       "followers_count    501\n",
       "dtype: int64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[df['statuses_count'] >= 5][['screen_name', 'statuses_count','followers_count']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HRMUA_flwrs = [f for idx, f in df_HRMUA.iterrows()]\n",
    "#HRMUA_texts, HRMUA_langs = get_twts_from_list_account_names(HRMUA_flwrs, max_num_followers=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_txts_langs_HRMUA = pd.DataFrame({'texts':HRMUA_texts, 'lang':HRMUA_langs})\n",
    "\n",
    "df_txts_langs_HRMUA.to_hdf('lang_data.h5', '/ukr_nodes/news/HromadskeUA/tls_followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_txts = pd.read_hdf('lang_data.h5', '/ukr_nodes/news/HromadskeUA/tls_followers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATALONIA NODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Catalonia_nodes = {}\n",
    "Catalonia_nodes['news'] = ['LaVanguardia', 'VilaWeb', 'diariARA', 'elperiodico',\n",
    "                           'elperiodico_cat', 'elpuntavui']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "country = 'cat'\n",
    "node_name = 'news'\n",
    "acc_name = 'elperiodico'\n",
    "rel_type = 'followers'\n",
    "\n",
    "path_save = '/'.join(['',country, node_name, acc_name, rel_type])\n",
    "followers = get_account_network(acc_name, rel_type=rel_type, \n",
    "                                max_num =5000, key_words=None)\n",
    "json_format = [elem._json for elem in followers]\n",
    "df = pd.DataFrame(json_format)\n",
    "df.to_hdf('lang_data.h5', path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_words=['Catal', 'Bcn', 'Barcel']\n",
    "followers = get_account_network(screen_name, rel_type='followers', \n",
    "                                max_num =5000, key_words=None)\n",
    "json_info = [elem._json for elem in followers]\n",
    "df = pd.DataFrame(json_info)\n",
    "df.to_hdf('lang_data.h5', path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ARA_followers = get_account_network('diariARA', rel_type='followers', \n",
    "                                       max_num =5000, key_words=None)\n",
    "json_info_ARA = [elem._json for elem in ARA_followers]\n",
    "df_ARA = pd.DataFrame(json_info_ARA)\n",
    "df_ARA.to_hdf('lang_data.h5', '/cat_nodes/news/diariARA/followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ARA_follwrs = pd.read_hdf('lang_data.h5', '/cat_nodes/news/diariARA/followers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "es       240\n",
       "ca       178\n",
       "en        41\n",
       "it         1\n",
       "fr         1\n",
       "en-GB      1\n",
       "Name: lang, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ARA_follwrs[df_ARA_follwrs['statuses_count'] > 5][['screen_name', 'statuses_count','followers_count']].count()\n",
    "df_ARA_follwrs['lang'][df_ARA_follwrs['statuses_count'] > 5][df_ARA_follwrs['location'].str.contains(r\"(Barcel|Catal)\")].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "counts_ARA_Cat = df_ARA['lang'][df_ARA['location'].str.contains(r\"(Barcel|Catal)\")].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13139999999999999"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ARA['lang'][df_ARA['location'].str.contains(r\"(Barcel|Catal|Tarr|Llei|Ger|Gir|Badal)\")].count()/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_LaVang[['lang', 'screen_name']][df_LaVang['location'].str.contains(r\"(Barcel|Catal)\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET TWEETS FROM FOLLOWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:15: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(79,)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country = 'ukr'\n",
    "node_name = 'starsystem'\n",
    "screen_name = 's_vakarchuk'\n",
    "rel_type1 = 'followers'\n",
    "rel_type2 = 'tls_followers'\n",
    "min_num_twts_per_acc=5\n",
    "\n",
    "path_load = '/'.join(['',country, node_name, screen_name, rel_type1])\n",
    "path_save = '/'.join(['',country, node_name, screen_name, rel_type2])\n",
    "\n",
    "key_words = {'ukr':r\"(Україна|Ukraine|Украина|Київ|Киев|Львів|Одес)\", \n",
    "             'cat':r\"(Barcel|Catal|Tarr|Llei|Ger|Gir|Badal)\"}\n",
    "df = pd.read_hdf('lang_data.h5', path_load)\n",
    "relevant_followers = df['screen_name'][df['statuses_count'] >= min_num_twts][\n",
    "                         df['location'].str.contains(key_words[country])\n",
    "                       ].values\n",
    "relevant_followers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ukr/starsystem/s_vakarchuk/followers'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tl_followers(screen_name, country, node_name, min_num_twts_per_acc=5, max_num_followers=None):\n",
    "    \"\"\" Creates pandas dataframe with all tweet texts and corresponding language\n",
    "    from followers of a given account. A dataframe with all followers info \n",
    "    must have been previously computed and saved in hdf5 format\"\"\"\n",
    "    base_path = '/'.join(['',country, node_name, screen_name])\n",
    "    path_load = base_path + '/followers'\n",
    "    path_save = base_path + '/tls_followers'\n",
    "    key_words = {'ukr':r\"(Україна|Ukraine|Украина|Київ|Киев|Львів|Одес)\", \n",
    "                 'cat':r\"(Barcel|Catal|Tarr|Llei|Ger|Gir|Badal)\"}\n",
    "    df = pd.read_hdf('lang_data.h5', path_load)\n",
    "    # filter by num_min_twts_per_account\n",
    "    relevant_followers = df['screen_name'][df['statuses_count'] >= min_num_twts_per_acc]\n",
    "    # keep only country residents\n",
    "    relevant_followers = relevant_followers[df['location'].str.contains(key_words[country])].values\n",
    "    texts, langs, auth = get_twts_from_list_account_names(relevant_followers, \n",
    "                                                          max_num_accounts=max_num_followers)\n",
    "    df_txts_langs= pd.DataFrame({'texts':texts, 'lang':langs, 'screen_name':auth})\n",
    "    df_txts_langs.to_hdf('lang_data.h5', path_save)\n",
    "    return df_txts_langs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_path = '/'.join(['',country, node_name, screen_name])\n",
    "path_load = base_path + '/followers'\n",
    "path_save = base_path + '/tls_followers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf('lang_data.h5', path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>Hi, my name is Tina✋. I'm 16 years old and i'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>It's my brother's birthday today!!! Yeeeeeey)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>When you have nothing to do https://t.co/vdK2e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uk</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>@SolomiaNB Звучить по-філософськи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ru</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>@IloveLHMelovin Подивись</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>uk</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>@SolomiaNB А це вже нагло</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>en</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>RT @KatieStrope96: Someone please take advanta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>uk</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>@SolomiaNB Вільна(мрій)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ru</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>@SolomiaNB От +</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ru</td>\n",
       "      <td>ChristinaVaAn</td>\n",
       "      <td>@Brizer_06 Ееееей, все добре?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ru</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>Ф.Киркоров и его \"жена\" https://t.co/WyKyrk6BC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ru</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>Фанатка Киркорова \"родила\" ему четверых детей ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ru</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>Не невеста а позорище какое то !!  Давай пожен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ru</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>@Club_FKirkorova Филипп я твоя жена🏍️🐱🦒🚗🚡 http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ru</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>Все хорошо https://t.co/pE4tPjGNZc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ru</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>@Club_FKirkorova Твоя жена Каролина Киркорова ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ru</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>Все окей!🐶🐻🐱🦒 https://t.co/vCLUjI4Ye5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ru</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>@vkontakte привет всем от Каролины Киркоровой!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>und</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>https://t.co/irhG18R41n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ru</td>\n",
       "      <td>y16BFIHiXerxBYD</td>\n",
       "      <td>@Pushistik_532 Привет девчонушка! https://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ru</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>RT @gor_lev: 14 июня\\nЛьвы - еще чуть-чуть пот...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ru</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>@CHURIKOVA_ ПХАХААХАХАХ, наверное больше чем я😂😂😂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ru</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>Мне кажется ,что перед ЗНО не так стрёмно было...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ru</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>Ребята,можно кому-то дам пароль и логин от лич...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ru</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>RT @StunningPosts: и вот ты в очередной раз ду...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ru</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>RT @VityanOneLove: Зачем идти на концерт,если ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ru</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>@alina_dymar чего я не могу ретвитнуть?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ru</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>@alina_dymar В июле❤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ru</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>RT @vacuumxfck: Жаль, что в Вконтакте нет функ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>und</td>\n",
       "      <td>nata_voytovich</td>\n",
       "      <td>RT @bvckl: https://t.co/2U0ZgIY7Yb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>@verkhovna_rada Рада проголосувала за мовні кв...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>RT @kievtypical: Сьогодні День пам’яті жертв п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>Навіть нічого додати.. https://t.co/DKdE7woHxc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>Раджу прочитати!\\n https://t.co/f2UdmlnuNq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>RT @brutfoot: ЗМІ: Голкіпер \"Манчестер Сіті\" К...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>RT @UPZhyttya: NASA показало приголомшливі зні...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>#перемога #respect Katie Melua британсько-груз...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>К- Криативно або як Київський Національний уні...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>“На польських підприємствах працюють від 10% д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>uk</td>\n",
       "      <td>Borys_ZV</td>\n",
       "      <td>Вічно перший Саша Шовковський #легенда #СаШо #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>en</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>Trying out @theTunnelBear so I can browse priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>und</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>RT @OJessicaNigri: 🙌❤ https://t.co/0usPTaeUZj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ru</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>Включите «Нирвану» погромче https://t.co/PHVZj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>und</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>Шарф СНУД крючком для начинающих Round Crochet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>en</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>RT @MCR_FANS: NEWS: The Black Parade/Living Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>cs</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>Thank you so much for the love с помощью @MCRo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>cs</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>The Black Parade Is Dead! (Full) - My Chemical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>ru</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>ИНОСТРАНЦЫ СЛУШАЮТ РУССКУЮ МУЗЫКУ #4 https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>ru</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>Как Быстро Выучить Английский https://t.co/tEu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>ru</td>\n",
       "      <td>Lex56679854</td>\n",
       "      <td>АМЕРИКАНЦЫ смотрят OXXXYMIRON - ГОРОД ПОД ПОДО...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>ru</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>Кого из знаменитостей ты бы хотел(-а) читать н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>ru</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>https://t.co/uSVH0wH463 вступи, и арт получи —...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>eu</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>ⓓⓔ¶☺ — Gofyqysjcjxhshdhdjcj https://t.co/kaIZD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>ru</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>Кто твой любимый художник? — Мой любимый\\nжудо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>ru</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>Продолжи фразу: “Знаете ли вы, что ...” — Вы д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>ru</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>Привет, помоги пожалуйста в развитии группы ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>ru</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>Привет, помоги пожалуйста в развитии группы ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>ru</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>Зайка, вступи пожалуйста https://t.co/sag700Io...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>ru</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>Способность, которой тебе бы хотелось обладать...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>ru</td>\n",
       "      <td>Dadik_Ma</td>\n",
       "      <td>Часто ли ты разочаровываешься в людях? — Ес ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>637 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    lang      screen_name                                              texts\n",
       "0     en    ChristinaVaAn  Hi, my name is Tina✋. I'm 16 years old and i'm...\n",
       "1     en    ChristinaVaAn      It's my brother's birthday today!!! Yeeeeeey)\n",
       "2     en    ChristinaVaAn  When you have nothing to do https://t.co/vdK2e...\n",
       "3     uk    ChristinaVaAn                  @SolomiaNB Звучить по-філософськи\n",
       "4     ru    ChristinaVaAn                           @IloveLHMelovin Подивись\n",
       "5     uk    ChristinaVaAn                          @SolomiaNB А це вже нагло\n",
       "6     en    ChristinaVaAn  RT @KatieStrope96: Someone please take advanta...\n",
       "7     uk    ChristinaVaAn                            @SolomiaNB Вільна(мрій)\n",
       "8     ru    ChristinaVaAn                                    @SolomiaNB От +\n",
       "9     ru    ChristinaVaAn                      @Brizer_06 Ееееей, все добре?\n",
       "10    ru  y16BFIHiXerxBYD  Ф.Киркоров и его \"жена\" https://t.co/WyKyrk6BC...\n",
       "11    ru  y16BFIHiXerxBYD  Фанатка Киркорова \"родила\" ему четверых детей ...\n",
       "12    ru  y16BFIHiXerxBYD  Не невеста а позорище какое то !!  Давай пожен...\n",
       "13    ru  y16BFIHiXerxBYD  @Club_FKirkorova Филипп я твоя жена🏍️🐱🦒🚗🚡 http...\n",
       "14    ru  y16BFIHiXerxBYD                 Все хорошо https://t.co/pE4tPjGNZc\n",
       "15    ru  y16BFIHiXerxBYD  @Club_FKirkorova Твоя жена Каролина Киркорова ...\n",
       "16    ru  y16BFIHiXerxBYD              Все окей!🐶🐻🐱🦒 https://t.co/vCLUjI4Ye5\n",
       "17    ru  y16BFIHiXerxBYD  @vkontakte привет всем от Каролины Киркоровой!...\n",
       "18   und  y16BFIHiXerxBYD                            https://t.co/irhG18R41n\n",
       "19    ru  y16BFIHiXerxBYD  @Pushistik_532 Привет девчонушка! https://t.co...\n",
       "20    ru   nata_voytovich  RT @gor_lev: 14 июня\\nЛьвы - еще чуть-чуть пот...\n",
       "21    ru   nata_voytovich  @CHURIKOVA_ ПХАХААХАХАХ, наверное больше чем я😂😂😂\n",
       "22    ru   nata_voytovich  Мне кажется ,что перед ЗНО не так стрёмно было...\n",
       "23    ru   nata_voytovich  Ребята,можно кому-то дам пароль и логин от лич...\n",
       "24    ru   nata_voytovich  RT @StunningPosts: и вот ты в очередной раз ду...\n",
       "25    ru   nata_voytovich  RT @VityanOneLove: Зачем идти на концерт,если ...\n",
       "26    ru   nata_voytovich            @alina_dymar чего я не могу ретвитнуть?\n",
       "27    ru   nata_voytovich                               @alina_dymar В июле❤\n",
       "28    ru   nata_voytovich  RT @vacuumxfck: Жаль, что в Вконтакте нет функ...\n",
       "29   und   nata_voytovich                 RT @bvckl: https://t.co/2U0ZgIY7Yb\n",
       "..   ...              ...                                                ...\n",
       "607   uk         Borys_ZV  @verkhovna_rada Рада проголосувала за мовні кв...\n",
       "608   uk         Borys_ZV  RT @kievtypical: Сьогодні День пам’яті жертв п...\n",
       "609   uk         Borys_ZV     Навіть нічого додати.. https://t.co/DKdE7woHxc\n",
       "610   uk         Borys_ZV         Раджу прочитати!\\n https://t.co/f2UdmlnuNq\n",
       "611   uk         Borys_ZV  RT @brutfoot: ЗМІ: Голкіпер \"Манчестер Сіті\" К...\n",
       "612   uk         Borys_ZV  RT @UPZhyttya: NASA показало приголомшливі зні...\n",
       "613   uk         Borys_ZV  #перемога #respect Katie Melua британсько-груз...\n",
       "614   uk         Borys_ZV  К- Криативно або як Київський Національний уні...\n",
       "615   uk         Borys_ZV  “На польських підприємствах працюють від 10% д...\n",
       "616   uk         Borys_ZV  Вічно перший Саша Шовковський #легенда #СаШо #...\n",
       "617   en      Lex56679854  Trying out @theTunnelBear so I can browse priv...\n",
       "618  und      Lex56679854      RT @OJessicaNigri: 🙌❤ https://t.co/0usPTaeUZj\n",
       "619   ru      Lex56679854  Включите «Нирвану» погромче https://t.co/PHVZj...\n",
       "620  und      Lex56679854  Шарф СНУД крючком для начинающих Round Crochet...\n",
       "621   en      Lex56679854  RT @MCR_FANS: NEWS: The Black Parade/Living Wi...\n",
       "622   cs      Lex56679854  Thank you so much for the love с помощью @MCRo...\n",
       "623   cs      Lex56679854  The Black Parade Is Dead! (Full) - My Chemical...\n",
       "624   ru      Lex56679854  ИНОСТРАНЦЫ СЛУШАЮТ РУССКУЮ МУЗЫКУ #4 https://t...\n",
       "625   ru      Lex56679854  Как Быстро Выучить Английский https://t.co/tEu...\n",
       "626   ru      Lex56679854  АМЕРИКАНЦЫ смотрят OXXXYMIRON - ГОРОД ПОД ПОДО...\n",
       "627   ru         Dadik_Ma  Кого из знаменитостей ты бы хотел(-а) читать н...\n",
       "628   ru         Dadik_Ma  https://t.co/uSVH0wH463 вступи, и арт получи —...\n",
       "629   eu         Dadik_Ma  ⓓⓔ¶☺ — Gofyqysjcjxhshdhdjcj https://t.co/kaIZD...\n",
       "630   ru         Dadik_Ma  Кто твой любимый художник? — Мой любимый\\nжудо...\n",
       "631   ru         Dadik_Ma  Продолжи фразу: “Знаете ли вы, что ...” — Вы д...\n",
       "632   ru         Dadik_Ma  Привет, помоги пожалуйста в развитии группы ht...\n",
       "633   ru         Dadik_Ma  Привет, помоги пожалуйста в развитии группы ht...\n",
       "634   ru         Dadik_Ma  Зайка, вступи пожалуйста https://t.co/sag700Io...\n",
       "635   ru         Dadik_Ma  Способность, которой тебе бы хотелось обладать...\n",
       "636   ru         Dadik_Ma  Часто ли ты разочаровываешься в людях? — Ес ht...\n",
       "\n",
       "[637 rows x 3 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:4: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "# filter followers to focus on most relevant ones\n",
    "min_num_twts = 5\n",
    "relevant_followers = df['screen_name'][df['statuses_count'] >= min_num_twts][\n",
    "                         df['location'].str.contains(key_words[country])\n",
    "                       ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0%                          100%\n",
      "[#####                         ] | ETA: 00:01:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter error response: status code = 401\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#########                     ] | ETA: 00:01:37"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[#############                 ] | ETA: 00:01:22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############                ] | ETA: 00:01:27"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[####################          ] | ETA: 00:00:50"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[######################        ] | ETA: 00:00:42"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[########################      ] | ETA: 00:00:33"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter error response: status code = 401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[##############################] | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:02:40\n"
     ]
    }
   ],
   "source": [
    "# get twts, lang, authors. Transform to pandas df and save\n",
    "texts, langs, auth = get_twts_from_list_account_names(relevant_followers, max_num_followers=79)\n",
    "df_txts_langs= pd.DataFrame({'texts':texts, 'lang':langs, 'screen_name':auth})\n",
    "df_txts_langs.to_hdf('lang_data.h5', path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_txts_langs['lang'].value_counts()\n",
    "#langs_detected = [detect(txt) for txt in df_txts_langs['texts']]\n",
    "\n",
    "langs_detected=[]\n",
    "for txt in df_txts_langs['texts']:\n",
    "    try:\n",
    "        langs_detected.append(detect(txt))\n",
    "    except:\n",
    "        langs_detected.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_try = pd.DataFrame({'a':['aaaa','bbbfdde',1],'b':[23,44,56]})\n",
    "df_try2 = pd.DataFrame({'a':['xxxx','zzzz'],'b':[3233,43214]})\n",
    "\n",
    "store = pd.HDFStore('try_hyerar.h5')\n",
    "\n",
    "store.append('city/topic', df_try)\n",
    "\n",
    "store.close()\n",
    "\n",
    "pd.read_hdf('try_hyerar.h5', 'city/topic')\n",
    "\n",
    "store = pd.HDFStore('try_hyerar.h5','a')\n",
    "\n",
    "store.append('city/topic', df_try2)\n",
    "\n",
    "store.close()\n",
    "\n",
    "pd.read_hdf('try_hyerar.h5', 'city/topic')\n",
    "\n",
    "store = pd.HDFStore('try_hyerar.h5','a')\n",
    "\n",
    "store.put('city/followers',df)\n",
    "\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### MY ACCOUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ca'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api = tweepy.API(auth)\n",
    "user_info = api.get_user('ArnauAndreu')  \n",
    "user_info._json['lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ukraine'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info._json['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_friends = get_account_network('ArnauAndreu')\n",
    "\n",
    "my_df = pd.DataFrame(my_followers)\n",
    "\n",
    "Counter([friend.lang for friend in my_friends])\n",
    "\n",
    "my_fr_txts, my_friends_lang = get_twts_from_list_account_names(my_friends)\n",
    "\n",
    "#Counter(my_friends_lang)\n",
    "\n",
    "\n",
    "\n",
    "# my_fr_langs_detected=[]\n",
    "# for i,txt in enumerate(my_fr_txts):\n",
    "#     #print(i, txt)\n",
    "#     try:\n",
    "#         my_fr_langs_detected.append(detect(txt))\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "#Counter(my_fr_langs_detected)\n",
    "\n",
    "usr_tl = get_account_timeline(my_friends[44].screen_name, max_num=10)\n",
    "\n",
    "df_try=pd.DataFrame([twt._json for twt in usr_tl])\n",
    "df_try.columns\n",
    "\n",
    "my_tl = get_account_timeline('ArnauAndreu', max_num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DYNAMO KIEV PLAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DYNAMO PLAYERS\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"http://www.worldfootball.net/teams/dinamo-kiev/2017/2/\"\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.text, \"lxml\")\n",
    "\n",
    "dynamo_players = pd.read_html(url, encoding='utf8')[1][2].dropna().values\n",
    "\n",
    "dynamo_players\n",
    "\n",
    "dyn_play_countr = pd.read_html(url, encoding='utf8')[1][[2,4]].dropna().values\n",
    "\n",
    "dyn_play_countr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PYMONGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "conn=MongoClient()\n",
    "\n",
    "#define database\n",
    "db = conn.citylangs\n",
    "\n",
    "#define collection inside database\n",
    "collection = db.bcn.ajuntam.followers\n",
    "\n",
    "# function to add documents to collection \n",
    "def make_followers_collection(account_name, collection, max_num=100):\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "    users = tweepy.Cursor(api.followers, screen_name=account_name).items(max_num)\n",
    "    #i = 0\n",
    "    while True:\n",
    "        try:\n",
    "            user = next(users)\n",
    "            collection.insert_one(user._json)\n",
    "        except tweepy.TweepError as e:\n",
    "            if 'Read timed out' in str(e):\n",
    "                print('fall here')\n",
    "                print(e)\n",
    "                time.sleep(5)\n",
    "            else:\n",
    "                time.sleep(60*16)\n",
    "                user = next(users)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        #print (\"@\" + user.screen_name)\n",
    "    #return collection\n",
    "\n",
    "make_followers_collection('bcn_ajuntament',collection, max_num=100)\n",
    "\n",
    "#check what databases are available\n",
    "conn.database_names()\n",
    "\n",
    "# available collections inside db\n",
    "db.collection_names()\n",
    "\n",
    "collection2 = db.kiev.ukrpravda\n",
    "\n",
    "make_followers_collection('ukrpravda_news',collection2, max_num=300)\n",
    "\n",
    "l = list(conn.citylangs.kiev.ukrpravda.find())\n",
    "\n",
    "Counter([obj['lang'] for obj in l])\n",
    "\n",
    "\n",
    "db.collection_names()\n",
    "\n",
    "#db.categories.insert_one({ \"_id\": \"ukr_pravda\", \"children\": [] })\n",
    "# db.categories.insert({ _id: \"avto_kiev\", children: [] })\n",
    "# db.categories.insert({ _id: \"kiev\", children: [\"ukr_pravda\", \"avto_kiev\"] })\n",
    "\n",
    "db['kiev'].insert_one({'avto_kiev':[],'vitklitschko':[]})\n",
    "\n",
    "db.collection_names()\n",
    "\n",
    "rr=list(db['bcn.ajuntam.followers'].find())\n",
    "\n",
    "db['kiev'].find_one()\n",
    "\n",
    "db['bcn.ajuntam.followers']\n",
    "\n",
    "conn.database_names()\n",
    "\n",
    "coll2 = db.countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get hdf database keys\n",
    "with pd.HDFStore('lang_data.h5','r') as f:\n",
    "    my_keys = f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ukr_nodes/news/BBC_ua/followers',\n",
       " '/ukr_nodes/news/BBC_ua/tls_followers',\n",
       " '/ukr_nodes/news/HromadskeUA/followers',\n",
       " '/ukr_nodes/news/HromadskeUA/tls_followers',\n",
       " '/ukr_nodes/news/LIGAnet/followers',\n",
       " '/ukr_nodes/news/LIGAnet/tls_followers',\n",
       " '/ukr_nodes/news/ukrpravda_news/followers',\n",
       " '/cat_nodes/news/LaVanguardia/followers',\n",
       " '/cat_nodes/news/LaVanguardia/tls_followers',\n",
       " '/cat_nodes/news/diariARA/followers',\n",
       " '/cat_nodes/news/diariARA/tls_followers']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'lang_data.h5'\n",
    "country = 'cat'\n",
    "acc_names = ['diariARA', 'LaVanguardia']\n",
    "load_node1 = '/' + country + '_nodes/news/' + acc_names[0] + '/tls_followers'\n",
    "load_node2 = '/' + country + '_nodes/news/' + acc_names[1] + '/tls_followers'\n",
    "\n",
    "df1 = pd.read_hdf(file_path, load_node1)\n",
    "df2 = pd.read_hdf(file_path, load_node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df1, df2, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44937, 2), (34461, 2), (12181, 2))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape, df1.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12a432550>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FACEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fb_token = 'EAADT8MeSHbsBAPi29inYYj1xZBsywhwduhm5XZA1jI07qzmPA7OLVPZBBtRDCPv7LTyUvhxWut5ztyZAS5lvNMUU'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
